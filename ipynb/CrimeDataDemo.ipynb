{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A notebook to proceed experiment on real dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import autograd\n",
    "from abc import ABCMeta, abstractmethod\n",
    "import kgof.util as util\n",
    "import kgof.data as data\n",
    "import kgof.density as density\n",
    "import kgof\n",
    "import kgof.goftest as gof\n",
    "import kgof.kernel as kernel\n",
    "import kgof.glo as glo\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import matplotlib.ticker as ticker\n",
    "import autograd.numpy as np\n",
    "import scipy.stats as stats\n",
    "from sklearn.neighbors import kde\n",
    "from sklearn import mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# font options\n",
    "font = {\n",
    "#     'family' : 'normal',\n",
    "    #'weight' : 'bold',\n",
    "    'size'   : 32\n",
    "}\n",
    "matplotlib.rc('font', **{'family': 'serif', 'serif': ['Computer Modern']})\n",
    "\n",
    "\n",
    "# matplotlib.use('cairo')\n",
    "matplotlib.rc('text', usetex=True)\n",
    "matplotlib.rcParams['text.usetex'] = True\n",
    "plt.rc('font', **font)\n",
    "plt.rc('lines', linewidth=2)\n",
    "# matplotlib.rcParams['ps.useafm'] = True\n",
    "# matplotlib.rcParams['pdf.use14corefonts'] = True\n",
    "\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def filter_crimetype(data, type = None):\n",
    "    if type is None:\n",
    "        data = data\n",
    "    else:\n",
    "        data = data[data[:,0] == type]\n",
    "    if len(data) == 1:\n",
    "        print \"No Crime Type found\"\n",
    "    else:\n",
    "        loc = data[:,1:].astype(float)\n",
    "        loc = np.nan_to_num(loc)\n",
    "        loc = loc[loc[:,0] != 0]\n",
    "        #Set City bound\n",
    "        loc = loc[loc[:,0] >-89]\n",
    "        loc = loc[loc[:,1] > 40]\n",
    "        return loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_visual(loc_train, loc_test, size=10000, bin_size = 40):\n",
    "    #Select Training data X, and Testing data T\n",
    "    ds = data.DSResample(loc_train)\n",
    "    dat, ind = ds.sample(size,seed=9,return_ind=True)\n",
    "    tr, te, Itr = dat.split_tr_te(tr_proportion=0.5, return_tr_ind = True)\n",
    "    X = tr.X\n",
    "    indx = ind[Itr]\n",
    "    T = te.X\n",
    "    Total = dat.X\n",
    "    ds_t = data.DSResample(loc_test)\n",
    "    T2 = ds_t.sample(size, seed = 9).X\n",
    "\n",
    "    X_H, X_x, X_y = np.histogram2d(X[:,0],X[:,1],bin_size)\n",
    "#     X_H = X_H/np.sum(X_H)\n",
    "    X_X, X_Y = np.meshgrid(X_x, X_y)\n",
    "\n",
    "    T_H, T_x, T_y = np.histogram2d(T[:,0],T[:,1],bin_size)\n",
    "#     T_H = T_H/np.sum(T_H)\n",
    "    T_X, T_Y = np.meshgrid(T_x, T_y)\n",
    "\n",
    "    T2_H, T2_x, T2_y = np.histogram2d(T2[:,0],T2[:,1],bin_size)\n",
    "    rat = len(T2)/len(X)\n",
    "    T2_H = T2_H/rat\n",
    "#     T2_H = T2_H/np.sum(T2_H)\n",
    "    T2_X, T2_Y = np.meshgrid(T2_x, T2_y)\n",
    "\n",
    "    vmax = max(np.max(X_H),np.max(T_H),np.max(T2_H))\n",
    "    norm_ = colors.Normalize(0,vmax)\n",
    "\n",
    "    plt.figure(figsize = (5,5))\n",
    "    hist = plt.pcolormesh(X_X,X_Y,X_H.T,norm=norm_)\n",
    "    plt.axis([X_x.min(), X_x.max(), X_y.min(), X_y.max()])\n",
    "    plt.title(\"Distribution of Training Set\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.figure(figsize = (5,5))\n",
    "    hist = plt.pcolormesh(T_X,T_Y,T_H.T,norm=norm_)\n",
    "    plt.axis([T_x.min(), T_x.max(), T_y.min(), T_y.max()])\n",
    "    plt.title(\"Distribution of Testing Set\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.figure(figsize = (6.3,5))\n",
    "    hist = plt.pcolormesh(T2_X,T2_Y,T2_H.T,norm=norm_)\n",
    "    plt.axis([T2_x.min(), T2_x.max(), T2_y.min(), T2_y.max()])\n",
    "    plt.title(\"Distribution of Second Year\")\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')\n",
    "    \n",
    "    return X,T,Total,T2,indx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_gmm(X, low = 140, high = 150, inter = 1):\n",
    "    #Fit mixture of gaussian on X, optimising the number of clusters k using cv on BIC\n",
    "    bic = []\n",
    "    lowest_bic = np.infty\n",
    "    n_components_range = range(low, high)\n",
    "    cv_types = ['spherical']\n",
    "    for cv_type in cv_types:\n",
    "        for n_components in n_components_range:\n",
    "            # Fit a Gaussian mixture with EM\n",
    "            gmm = mixture.GaussianMixture(n_components=inter*n_components,\n",
    "                                          covariance_type=cv_type,random_state=3)\n",
    "            gmm.fit(X)\n",
    "            bic.append(gmm.bic(X))\n",
    "            if bic[-1] < lowest_bic:\n",
    "                lowest_bic = bic[-1]\n",
    "                best_gmm = gmm\n",
    "    return best_gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_test(best_gmm, T, J = 1, opt=False, alpha = 0.05, Linear=True):\n",
    "    # Setup the test on T\n",
    "    seed = 4\n",
    "    mean = best_gmm.means_\n",
    "    variance = best_gmm.covariances_\n",
    "    weight = best_gmm.weights_\n",
    "    IsoGM = density.IsoGaussianMixture(means = mean, variances = variance,pmix=weight)\n",
    "    ds = data.DSResample(T)\n",
    "    dat = ds.sample(len(T))\n",
    "    tr, te = dat.split_tr_te(tr_proportion=0.2, seed=seed+1)\n",
    "    \n",
    "    gwidth0 = util.meddistance(dat.X, subsample=1000)**2\n",
    "    null_sim = gof.FSSDH0SimCovObs(n_simulate=1000, seed=10)\n",
    "    if Linear is True:\n",
    "        if opt is False:\n",
    "            # random test locations\n",
    "            V0 = util.fit_gaussian_draw(dat.X, J, seed=seed+1)\n",
    "            k0 = kernel.KGauss(gwidth0)\n",
    "            fssd = gof.FSSD(IsoGM, k0, V0, null_sim=null_sim, alpha=alpha)\n",
    "            fssd_result = fssd.perform_test(dat)\n",
    "            return fssd_result, V0, gwidth0\n",
    "        else:\n",
    "            opts = {\n",
    "            'reg': 1e-1,\n",
    "            'max_iter': 50, \n",
    "            'tol_fun':1e-7, \n",
    "            'disp':True,\n",
    "            'gwidth_lb': 5e-4,\n",
    "            'gwidth_ub': 1e-1}\n",
    "            #Pick V0 randomly from training set to start with\n",
    "            with util.NumpySeedContext(seed=seed+10):\n",
    "                idx = np.random.choice(len(tr.X), size=J)\n",
    "            V0 = tr.X[idx,:]\n",
    "#             V0 = mean[:J,:]\n",
    "            V_opt, gw_opt, opt_result = gof.GaussFSSD.optimize_locs_widths(IsoGM, tr, gwidth0, V0, **opts)\n",
    "            k_opt = kernel.KGauss(gw_opt)\n",
    "            fssd_opt = gof.FSSD(IsoGM, k_opt, V_opt, null_sim=null_sim, alpha=alpha)\n",
    "            fssd_opt_result = fssd_opt.perform_test(dat, return_simulated_stats=False)\n",
    "            return fssd_opt_result, V_opt, gw_opt\n",
    "        \n",
    "    else:\n",
    "        sig2 = util.meddistance(X, subsample=1000)**2\n",
    "        k = kernel.KGauss(sig2)\n",
    "        bootstrapper = gof.bootstrapper_rademacher\n",
    "        kstein = gof.KernelSteinTest(IsoGM, k, bootstrapper=bootstrapper, \n",
    "                                     alpha=alpha, n_simulate=1100, seed=seed+1)\n",
    "        kstein_result = kstein.perform_test(dat, return_simulated_stats=False,\n",
    "                                           return_ustat_gram=True)\n",
    "        return kstein_result, bootstrapper, sig2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def interp_plot(V_opt, T2, X, best_gmm, bin_size = 30, fitted_sample = True, scale=1.1,zoom=False):\n",
    "    #Normalise count to density\n",
    "    seed = 4\n",
    "    np.random.seed(seed)\n",
    "    X_H, X_x, X_y = np.histogram2d(X[:,0],X[:,1],bin_size)\n",
    "    X_X, X_Y = np.meshgrid(X_x, X_y)\n",
    "#     X_H = X_H/np.sum(X_H)\n",
    "    \n",
    "    if fitted_sample is True:\n",
    "        sample_size = int(len(X)*scale)\n",
    "        sample = best_gmm.sample(sample_size)\n",
    "        samples = zoom_in(X_x.min(), X_x.max(), X_y.min(), X_y.max(),sample[0])\n",
    "        if len(samples) < len(X):\n",
    "            raise NameError('Samples not enough')\n",
    "        else:\n",
    "            dss = data.DSResample(samples)\n",
    "            samples = dss.sample(len(X)).X\n",
    "        Z,Z_x,Z_y = np.histogram2d(samples[:,0],samples[:,1],bin_size)\n",
    "        Z_X, Z_Y = np.meshgrid(Z_x, Z_y)\n",
    "    else:\n",
    "        x = np.linspace(np.min(X[:,0]), np.max(X[:,0]),bin_size)\n",
    "        y = np.linspace(np.min(X[:,1]), np.max(X[:,1]),bin_size)\n",
    "        Z_x, Z_y = np.meshgrid(x, y)\n",
    "        XX = np.array([Z_x.ravel(), Z_y.ravel()]).T\n",
    "        Z = np.exp(best_gmm.score_samples(XX))\n",
    "#         Z = Z.clip(min=1)-1\n",
    "        Z = Z.reshape(Z_x.shape).T\n",
    "#     Z = Z/np.sum(Z)\n",
    "\n",
    "    T_H, T_x, T_y = np.histogram2d(T2[:,0],T2[:,1],bin_size)\n",
    "    T_X, T_Y = np.meshgrid(T_x, T_y)\n",
    "    rat = len(T2)/float(len(X))\n",
    "    T_H = T_H/rat\n",
    "#     T_H = T_H/np.sum(T_H)\n",
    "    \n",
    "    vmax = max(np.max(X_H),np.max(T_H),np.max(Z))\n",
    "    norm_ = colors.Normalize(0,vmax)\n",
    "    \n",
    "    xmin = max(X_x.min(),T_x.min(),Z_x.min())\n",
    "    xmax = min(X_x.max(),T_x.max(),Z_x.max())\n",
    "    ymin = max(X_y.min(),T_y.min(),Z_y.min())\n",
    "    ymax = min(X_y.max(),T_y.max(),Z_y.max())\n",
    "    xs = np.linspace(xmin,xmax,4)\n",
    "    ys = np.linspace(ymin,ymax,4)\n",
    "    font_size = 20\n",
    "    if zoom is True:\n",
    "        z = '_Zoomed_In'\n",
    "    else:\n",
    "        z = ''\n",
    "    \n",
    "    #Plot density histogram\n",
    "    plt.figure(figsize = (5,5))\n",
    "#     hist = plt.hist2d(X[:,0],X[:,1],bin_size,norm=norm_)\n",
    "    plt.pcolormesh(X_X,X_Y,X_H.T,norm=norm_)\n",
    "    plt.axis([xmin, xmax, ymin, ymax])\n",
    "    plt.xticks(xs)\n",
    "    plt.yticks(ys)\n",
    "    ax = plt.gca()\n",
    "    xax = ax.get_xaxis()\n",
    "    yax = ax.get_yaxis()\n",
    "    xax.set_ticklabels(['%.2f'%x for x in xs],fontsize=font_size)\n",
    "    yax.set_ticklabels(['%.2f'%x for x in ys],fontsize=font_size)\n",
    "    plot_name = \"Distribution_of_Training_Set\" + z\n",
    "#     plt.title(plot_name)\n",
    "    plt.savefig(plot_name+'.pdf',bbox='tight')   \n",
    "    \n",
    "    plt.figure(figsize = (5,5))\n",
    "#     CS = plt.contourf(Z_x, Z_y, Z)\n",
    "    plt.pcolormesh(Z_x, Z_y, Z.T, norm=norm_)\n",
    "    plt.axis([xmin, xmax, ymin, ymax])\n",
    "    plt.xticks(xs)\n",
    "    plt.yticks(ys)    \n",
    "    ax = plt.gca()\n",
    "    xax = ax.get_xaxis()\n",
    "    yax = ax.get_yaxis()\n",
    "    xax.set_ticklabels(['%.2f'%x for x in xs],fontsize=font_size)\n",
    "    yax.set_ticklabels(['%.2f'%x for x in ys],fontsize=font_size)\n",
    "    plot_name = \"Fitted_Gaussian_Mixture\" + z\n",
    "#     plt.title(plot_name)\n",
    "    plt.savefig(plot_name+'.pdf',bbox='tight')\n",
    "    \n",
    "    plt.figure(figsize = (6.3,5))\n",
    "#     hist = plt.hist2d(T2[:,0],T2[:,1],bin_size,norm=norm_)\n",
    "    plt.pcolormesh(T_X,T_Y,T_H.T,norm=norm_)\n",
    "    plt.axis([xmin, xmax, ymin, ymax])\n",
    "    plt.xticks(xs)\n",
    "    plt.yticks(ys)\n",
    "    ax = plt.gca()\n",
    "    xax = ax.get_xaxis()\n",
    "    yax = ax.get_yaxis()\n",
    "    xax.set_ticklabels(['%.2f'%x for x in xs],fontsize=font_size)\n",
    "    yax.set_ticklabels(['%.2f'%x for x in ys],fontsize=font_size)\n",
    "    plt.colorbar()\n",
    "    plt.plot(V_opt[:,0], V_opt[:,1], 'w*', markersize=25, alpha=0.6)\n",
    "    plot_name = \"Interpretable_Location\" + z\n",
    "#     plt.title(plot_name)\n",
    "    plt.savefig(plot_name+'.pdf',bbox='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def power_check(loc, bmm, indx = None, itr=10, alpha = 0.05, opt=False, Linear = True):\n",
    "    rej = 0\n",
    "    rej_quad = 0\n",
    "    fssd_res = []\n",
    "    if indx is None:\n",
    "        test = loc\n",
    "    else:\n",
    "        mask = np.ones(len(loc), np.bool)\n",
    "        mask[indx] = 0\n",
    "        test = loc[mask]\n",
    "    with util.NumpySeedContext(seed=48):\n",
    "        for i in range(itr):\n",
    "            ds = data.DSResample(test)\n",
    "            dat = ds.sample(len(indx),np.random.randint(len(test)))\n",
    "            fssd = run_test(best_gmm, dat.X, opt=opt, alpha = alpha, Linear = Linear)\n",
    "            fssd_res.append(fssd)\n",
    "            rej += fssd[0]['h0_rejected']\n",
    "    return rej, fssd_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def zoom_in(x_low,x_high,y_low,y_high,loc):\n",
    "    loc = loc[loc[:,0] > x_low]\n",
    "    loc = loc[loc[:,1] > y_low]\n",
    "    loc = loc[loc[:,0] < x_high]\n",
    "    loc = loc[loc[:,1] < y_high]\n",
    "    return loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chicago Crime Dataset is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Extract data from pre-processed .npz file\n",
    "dd_new = np.load(glo.data_file('chicago_crime_loc_with_type2016.npz'))['data']\n",
    "dd_old = np.load(glo.data_file('chicago_crime_loc_with_type2014.npz'))['data']\n",
    "old_year = 2014\n",
    "new_year = 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def crime_count(data, n=10000):\n",
    "    z = data[:,0]\n",
    "    count = Counter(z)\n",
    "    interest = []\n",
    "    for i in enumerate(count):\n",
    "        if count[i[1]] > n:\n",
    "            interest.append([i[1],count[i[1]]])\n",
    "    return interest\n",
    "interestnew = crime_count(dd_new)\n",
    "interestold = crime_count(dd_old)\n",
    "print 'old_year:', interestold\n",
    "print 'new_year:',interestnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Choose the type of Crime category if necessary and proceed\n",
    "c_type = 'BURGLARY'\n",
    "size = 10000\n",
    "loc_old = filter_crimetype(dd_old, c_type)\n",
    "loc_new = filter_crimetype(dd_new, c_type)\n",
    "\n",
    "#Extract Training, Testing dataset and necessary index\n",
    "X,T,Total,T2,indx = run_visual(loc_old,loc_new,size=size, bin_size=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Build the Gaussian Miture model\n",
    "best_gmm = fit_gmm(X,low = 38, high = 39, inter=1)\n",
    "n_comp = best_gmm.n_components\n",
    "best_gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Test this year\n",
    "fssd_this_year = run_test(best_gmm,T,opt=False)\n",
    "fssd_this_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Check power on the FSSD for fitted model\n",
    "# iteration = 20\n",
    "# rej, fssd_res= power_check(loc_old, bmm = best_gmm, indx = indx, itr = iteration, \\\n",
    "#                            alpha = 0.05, opt=True, Linear = True)\n",
    "# rate = rej/float(iteration)\n",
    "# print rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Check power on original quadratic time KSTein Test\n",
    "# iteration = 20\n",
    "# rej_quad, fssd_res_quad= power_check(loc_old, bmm = best_gmm, indx = indx, itr = iteration, \\\n",
    "#                            alpha = 0.05, opt=True, Linear = False)\n",
    "# rate_quad = rej_quad/float(iteration)\n",
    "# print rate_quad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Fit the model \n",
    "best_gmm = fit_gmm(Total,low = n_comp, high = n_comp+1, inter=1)\n",
    "best_gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Test on next year data without optimised location\n",
    "fssd_next_year = run_test(best_gmm, T2)\n",
    "fssd_next_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Test on next year data with optimised location\n",
    "n_points = 1\n",
    "fssd_next_year_opt, V_opt, gw_opt = run_test(best_gmm, T2, J=n_points, opt=True)\n",
    "fssd_next_year_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "V_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gw_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the intensity, samples from fitted model and test location on testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "interp_plot(V_opt,T2, Total, best_gmm = best_gmm, bin_size = 40, fitted_sample=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible V_opt location:\n",
    "\n",
    "[[-87.77217121,  42.01658179],\n",
    "\n",
    "[-87.59425177,  41.78447888]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zoom in the region around optimised testing location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "box_size = 0.07\n",
    "V_loc = V_opt[0,:]\n",
    "\n",
    "x_low = V_loc[0] - box_size\n",
    "x_high = V_loc[0] + box_size\n",
    "y_low = V_loc[1] - box_size\n",
    "y_high = V_loc[1] + box_size\n",
    "Total_zoom = zoom_in(x_low,x_high,y_low,y_high,Total)\n",
    "T2_zoom = zoom_in(x_low,x_high,y_low,y_high,T2)\n",
    "\n",
    "scale = float(len(Total))/len(Total_zoom)*2\n",
    "interp_plot(V_opt,T2_zoom, Total_zoom, best_gmm = best_gmm, bin_size = 40, \\\n",
    "            fitted_sample=False, scale = scale, zoom=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save results in .npz file\n",
    "# np.savez('chicago_'+str(c_type)+'comparison_with'+str(n_comp)+'GMM'+str(n_points)+'locations.npz',\\\n",
    "#          crime_type = c_type, old_year = old_year, new_year = new_year, V_opt = V_opt, n_comp = n_comp, gw_opt = gw_opt,\\\n",
    "#          fssd_this_year = fssd_this_year, fssd_next_year = fssd_next_year, fssd_next_year_opt = fssd_next_year_opt)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
